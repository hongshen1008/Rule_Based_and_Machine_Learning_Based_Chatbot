{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0043c7-3ded-43d8-b36f-79070770437c",
   "metadata": {},
   "source": [
    "# Machine Learning Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c69a93-2969-411c-b599-03c9c8ae7716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://medium.com/@rr_42830/build-your-own-chatbot-using-deep-learning-23a022638067\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d4c17e-2c83-47ee-ab53-9f17dba8b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model(data):\n",
    "    # extract data from json file\n",
    "    training_sentences = []\n",
    "    training_labels = []\n",
    "    labels = []\n",
    "    responses = []\n",
    "\n",
    "\n",
    "    for intent in data['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            training_sentences.append(pattern)\n",
    "            training_labels.append(intent['tag'])\n",
    "        responses.append(intent['responses'])\n",
    "\n",
    "        if intent['tag'] not in labels:\n",
    "            labels.append(intent['tag'])\n",
    "\n",
    "    num_classes = len(labels)\n",
    "\n",
    "    # fit transform to BOW\n",
    "    lbl_encoder = LabelEncoder() # convert categorical variables to numerical labels (\"greeting\", \"bye\", \"thanks\") -> (0, 1, 2)\n",
    "    lbl_encoder.fit(training_labels) \n",
    "    training_labels = lbl_encoder.transform(training_labels)\n",
    "    training_labels = keras.utils.to_categorical(training_labels, num_classes=num_classes) # convert to bow model (binary representation)\n",
    "\n",
    "    vocab_size = 1000\n",
    "    embedding_dim = 20\n",
    "    max_len = 20\n",
    "    oov_token = \"<OOV>\" # out of vocabulary token value\n",
    "\n",
    "    # tokenizing text, converting words to lowercase, filtering out punctuation, and converting text into sequences of integers\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token) \n",
    "    tokenizer.fit_on_texts(training_sentences)\n",
    "    word_index = tokenizer.word_index\n",
    "    sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "    padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)\n",
    "    \n",
    "    train_data = padded_sequences\n",
    "    train_labels = training_labels\n",
    "    \n",
    "    # LSTM model\n",
    "    model = keras.Sequential([\n",
    "        Embedding(len(word_index)+1, embedding_dim, input_length=max_len),\n",
    "        LSTM(embedding_dim),\n",
    "        Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.fit(train_data, train_labels, epochs=150, verbose=0)\n",
    "    \n",
    "    return model, lbl_encoder, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f84d03-34ac-479b-a8f7-450f38d48a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openMenu():\n",
    "    with open('Beverage_Menu.txt', 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621e59da-b668-46f3-ab8a-81f5251b660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name Entity Recognision (NER)\n",
    "def NER(query):\n",
    "    name_entity = []\n",
    "    words =  nltk.word_tokenize(query)\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    chunked = nltk.ne_chunk(tagged, binary=False)\n",
    "    for chunk in chunked.leaves():\n",
    "        if hasattr(chunk, 'label') or chunk[1] == 'NNP':\n",
    "            name_entity.append(chunk[0])\n",
    "                \n",
    "    userName = ' ' + ' '.join(name for name in name_entity)\n",
    "    return userName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a052994-5970-48a4-b5a1-16680e738c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectMisspelledWord(query, menuPrice):\n",
    "    # !pip install fuzzywuzzy\n",
    "    from fuzzywuzzy import fuzz\n",
    "    \n",
    "    matching_items = []\n",
    "    query = query.lower().split()\n",
    "    print(query)\n",
    "    for word in query:\n",
    "        for item in menuPrice.keys():\n",
    "            match_score = fuzz.token_set_ratio(word, item.lower()) # Calculate fuzzy match score between user query and coffee item\n",
    "            if match_score > 80:\n",
    "                if item not in matching_items:\n",
    "                    matching_items.append(item.title())\n",
    "    return matching_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c2120f-f5d1-496b-b0d1-6747e0b5c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect number in user query\n",
    "def detectNumber(query):\n",
    "    num_dict = {\"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\":6, \"seven\":7, \"eight\":8, \"nine\":9, \"ten\":10} # number dictionary\n",
    "    \n",
    "    quantity = []\n",
    "    for word in query.split():\n",
    "        if word.isdigit():\n",
    "            quantity += [int(word)]\n",
    "        else:\n",
    "            for w in num_dict:\n",
    "                if w == word:\n",
    "                    quantity += [num_dict[word]]\n",
    "    return quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e81697-6b43-4430-8778-6fc37e01cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction function\n",
    "\n",
    "def transaction(queryList, model2, tokenizer2, lbl_encoder2):\n",
    "     \n",
    "    menuPrice = {\"Espresso\": 1.50, \"Americano\": 1.50, \"Cappuccino\": 1.80, \"Latte\": 1.80, \"Macchiato\": 1.80, \"Flat White\": 2.10, \"Mocha\": 2.10, \"Black Tea\": 1.50}\n",
    "\n",
    "    lastQuery = queryList[0]\n",
    "    currentQuery = queryList[1]\n",
    "    \n",
    "    switch = True    \n",
    "    while switch == True:\n",
    "        # Detect quantity in user query\n",
    "        temp_query = currentQuery\n",
    "        quantity = detectNumber(temp_query)        \n",
    "        \n",
    "        print(quantity)\n",
    "        # Detect misspelled beverage\n",
    "        beverages = detectMisspelledWord(currentQuery, menuPrice)\n",
    "        if len(beverages) == 0:\n",
    "            beverages = detectMisspelledWord(lastQuery, menuPrice)\n",
    "        \n",
    "        if len(beverages) == 0:\n",
    "            print('\\nSorry, your order does not appear in our menu.')\n",
    "            return True\n",
    "        \n",
    "        # Assume 1 for all beverage if no number detected\n",
    "        if(len(quantity) == 0):\n",
    "            for i in beverages:\n",
    "                quantity += [1]   \n",
    "    \n",
    "        if len(quantity)!=0 and len(quantity) == len(beverages):\n",
    "            # Find price of each beverage\n",
    "            price = []\n",
    "            for i, j in menuPrice.items():\n",
    "                for k in beverages:\n",
    "                    if k == i:\n",
    "                        price += [j]\n",
    "\n",
    "            #Calculate total price\n",
    "            totalPrice = sum([p*q for p, q in zip(price, quantity)])\n",
    "\n",
    "            print(\"\\n{:<10} {:<15} {:<10}\".format('Quantity', 'Beverage', 'Price'))\n",
    "            print(\"----------------------------------\\n\")\n",
    "            for i in range(len(price)):\n",
    "                print(\"{:<10} {:<15} £{:<10.2f}\".format(quantity[i], beverages[i], price[i]))\n",
    "            print('\\nTotal price is: £', \"{:.2f}\".format(totalPrice))\n",
    "            flag = True\n",
    "            while(flag == True):\n",
    "                print('\\nGroovy:\\nGreat! Please confirm your item, quantity and total price (e.g. yes/no). If you want to exit transaction, type quit. :')\n",
    "                confirmation = input().lower()\n",
    "                prediction = model2.predict(pad_sequences(tokenizer2.texts_to_sequences([confirmation]), truncating='post', maxlen=20), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "                tag = lbl_encoder2.inverse_transform([np.argmax(prediction)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "                print(tag)\n",
    "                if ('quit' in confirmation):\n",
    "                    flag = False\n",
    "                    return False\n",
    "                elif(tag == \"positive\"):\n",
    "                    flag = False\n",
    "                    print(\"\\nThank you! Your order has been confirmed.\")\n",
    "                    return False\n",
    "                else:\n",
    "                    print('\\nWould you like to reorder?')\n",
    "                    reorder_query = input(\"\\nUser:\\n\")\n",
    "                    returnFlag = feedback(reorder_query, model2, tokenizer2, lbl_encoder2)\n",
    "                    flag = False\n",
    "                    return returnFlag\n",
    "                           \n",
    "            switch = False\n",
    "        else:\n",
    "            print(\"Groovy:\\nPlease specify the quantity of each item (e.g. 2 mocha and 1 americano). If you want to exit transaction, type quit.\")\n",
    "            query = input(\"\\nUser:\\n\").lower()\n",
    "            if \"quit\" in query:\n",
    "                return False\n",
    "            else:\n",
    "                lastQuery = currentQuery\n",
    "                currentQuery = query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63726539-c922-4049-b2c6-18cb54d1f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback(query, model2, tokenizer2, lbl_encoder2):\n",
    "    prediction = model2.predict(pad_sequences(tokenizer2.texts_to_sequences([query]), truncating='post', maxlen=20), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "    tag = lbl_encoder2.inverse_transform([np.argmax(prediction)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "    print(tag)\n",
    "    if (tag == \"positive\"):\n",
    "        returnFlag = True\n",
    "        return returnFlag\n",
    "    elif (tag == \"negative\"):\n",
    "        returnFlag = False\n",
    "        return returnFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4df368fb-20f1-4e78-a8ad-63b60f6a79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def chat():\n",
    "    with open('intent.json', encoding='utf-8') as file:\n",
    "        data1 = json.load(file)\n",
    "        \n",
    "    with open('PositiveNegativeData.json', encoding='utf-8') as file1:\n",
    "        data2 = json.load(file1)\n",
    "    \n",
    "    model1, lbl_encoder1, tokenizer1 = model(data1)\n",
    "    model2, lbl_encoder2, tokenizer2 = model(data2)\n",
    "    \n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    queryList = [\"\",\"\"]\n",
    "    newName = \"\"\n",
    "    flag1 = True\n",
    "    flag2 = False\n",
    "    print(\"Groovy:\\nHello, welcome to Chin's Coffee House! What is your name?\")\n",
    "    query = input(\"\\nUser:\\n\")\n",
    "    name = NER(query)\n",
    "    while flag1:\n",
    "        if flag2 == True:\n",
    "            print('\\nGroovy:\\nWhat would you like to order? If you want to exit, type quit.')\n",
    "            query = input(\"\\nUser:\\n\")\n",
    "            flag2 = False\n",
    "        else:\n",
    "            print('\\nGroovy:\\nHi'+ (newName if len(newName)!=0 else name) +\". Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\")\n",
    "            query = input(\"\\nUser:\\n\")\n",
    "            \n",
    "        if query.lower() == \"quit\":\n",
    "            flag1 = False\n",
    "            print(\"\\nGroovy:\\nThank you for visiting Chin's Coffee House. What do you think of my service?\")\n",
    "            query = input(\"\\nUser:\\n\")\n",
    "            prediction = feedback(query, model2, tokenizer2, lbl_encoder2)\n",
    "            if(prediction==True):\n",
    "                print('\\nGroovy:\\nThank you for your feedback, I am glad to hear that!')\n",
    "            else:\n",
    "                print('\\nGroovy:\\nI am sorry to hear that, I will feedback to my company.')\n",
    "            print(\"Bye, take care\"+ (newName if len(newName)!=0 else name))\n",
    "        else:\n",
    "            queryList[0] = queryList[1]\n",
    "            queryList[1] = query.lower()\n",
    "            \n",
    "            result = model1.predict(pad_sequences(tokenizer1.texts_to_sequences([query]), truncating='post', maxlen=max_len), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "            tag = lbl_encoder1.inverse_transform([np.argmax(result)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "\n",
    "            for i in data1['intents']:\n",
    "                if i['tag'] == tag:\n",
    "                    print(tag)\n",
    "                    response = np.random.choice(i['responses'])\n",
    "                    if response == \"Menu\":\n",
    "                        openMenu()                  \n",
    "                        flag2 = True\n",
    "                    elif response == \"transaction\":\n",
    "                        print(queryList)\n",
    "                        flag2 = transaction(queryList, model2, tokenizer2, lbl_encoder2)\n",
    "                    elif response == \"username\":\n",
    "                        print(\"\\nGroovy:\\nYour name is\" + (newName if len(newName)!= 0 else name) + \".\")\n",
    "                    elif response == \"Change name\":\n",
    "                        newName = NER(query)\n",
    "                        print(\"\\nGroovy:\\nNoted, your name is\" + (newName if len(newName)!= 0 else name) + \".\")\n",
    "                    else:\n",
    "                        print(\"Groovy:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02fb902-3381-4e07-9701-2bd53ef02fe1",
   "metadata": {},
   "source": [
    "## Run the chatbot here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c30f7863-4268-4302-9bbb-c6c9bd33faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groovy:\n",
      "Hello, welcome to Chin's Coffee House! What is your name?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " I am JJ lin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Groovy:\n",
      "Hi JJ. Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " can i have  a black tea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ananconda\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transaction']\n",
      "['', 'can i have  a black tea']\n",
      "[]\n",
      "['can', 'i', 'have', 'a', 'black', 'tea']\n",
      "\n",
      "Quantity   Beverage        Price     \n",
      "----------------------------------\n",
      "\n",
      "1          Black Tea       £1.50      \n",
      "\n",
      "Total price is: £ 1.50\n",
      "\n",
      "Groovy:\n",
      "Great! Please confirm your item, quantity and total price (e.g. yes/no). If you want to exit transaction, type quit. :\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " thats right\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative']\n",
      "\n",
      "Would you like to reorder?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n",
      "\n",
      "Groovy:\n",
      "What would you like to order? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " a flat white\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flat white']\n",
      "Groovy:\n",
      " A flat white is a blend of micro-foamed milk poured over a single or double shot of espresso.\n",
      "\n",
      "Groovy:\n",
      "Hi JJ. Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " give me a flat white\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['help']\n",
      "Groovy:\n",
      " I can have a small talk, help to take order and answer some questions regarding the beverages!\n",
      "\n",
      "Groovy:\n",
      "Hi JJ. Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " i would like to have a flat whit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transaction']\n",
      "['give me a flat white', 'i would like to have a flat whit']\n",
      "[]\n",
      "['i', 'would', 'like', 'to', 'have', 'a', 'flat', 'whit']\n",
      "\n",
      "Quantity   Beverage        Price     \n",
      "----------------------------------\n",
      "\n",
      "1          Flat White      £2.10      \n",
      "\n",
      "Total price is: £ 2.10\n",
      "\n",
      "Groovy:\n",
      "Great! Please confirm your item, quantity and total price (e.g. yes/no). If you want to exit transaction, type quit. :\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " that's right\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative']\n",
      "\n",
      "Would you like to reorder?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative']\n",
      "\n",
      "Groovy:\n",
      "Hi JJ. Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " what is americano\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['americano']\n",
      "Groovy:\n",
      " Americano also called as black coffee. It is simply just hot water and espresso. It will be served half espresso to half water.\n",
      "\n",
      "Groovy:\n",
      "Hi JJ. Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " how much is it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cappuccino price']\n",
      "Groovy:\n",
      " A cup of Cappuccino is £1.80\n",
      "\n",
      "Groovy:\n",
      "Hi JJ. Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " can i have one of it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transaction']\n",
      "['how much is it', 'can i have one of it']\n",
      "[1]\n",
      "['can', 'i', 'have', 'one', 'of', 'it']\n",
      "['how', 'much', 'is', 'it']\n",
      "\n",
      "Sorry, your order does not appear in our menu.\n",
      "\n",
      "Groovy:\n",
      "What would you like to order? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " can i have a cup of cappucino\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transaction']\n",
      "['can i have one of it', 'can i have a cup of cappucino']\n",
      "[]\n",
      "['can', 'i', 'have', 'a', 'cup', 'of', 'cappucino']\n",
      "\n",
      "Quantity   Beverage        Price     \n",
      "----------------------------------\n",
      "\n",
      "1          Cappuccino      £1.80      \n",
      "\n",
      "Total price is: £ 1.80\n",
      "\n",
      "Groovy:\n",
      "Great! Please confirm your item, quantity and total price (e.g. yes/no). If you want to exit transaction, type quit. :\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " thats correct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n",
      "\n",
      "Thank you! Your order has been confirmed.\n",
      "\n",
      "Groovy:\n",
      "Hi JJ. Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Groovy:\n",
      "Thank you for visiting Chin's Coffee House. What do you think of my service?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " quite ok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Bye, take care JJ\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be49884d-99c9-40c7-8e8c-33e7ee94dfa8",
   "metadata": {},
   "source": [
    "# Experiments: Machine Learning Chatbot Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be8fa3-bd2c-4474-b188-9a5a09d0e4b6",
   "metadata": {},
   "source": [
    "## Evaluation of intent matching with correct English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1ea9039-e188-443f-9805-c60fc1697463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'smalltalk', 'formalgreeting', 'formalgreeting', 'help', 'username', 'chatbot', 'chatbot', 'help', 'americano', 'mocha', 'coffee bean', 'espresso price', 'recommendation', 'latte', 'decaf', 'menu', 'menu', 'transaction', 'transaction', 'transaction', 'transaction', 'transaction', 'transaction', 'changename', 'changename', 'changename', 'changename', 'changename', 'changename']\n",
      "\n",
      "\n",
      "['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'recommendation', 'smalltalk', 'formalgreeting', 'formalgreeting', 'help', 'username', 'chatbot', 'chatbot', 'menu', 'americano', 'transaction', 'coffee bean', 'espresso price', 'recommendation', 'cappuccino price', 'decaf', 'menu', 'menu', 'transaction', 'transaction', 'transaction', 'decaf', 'transaction', 'greeting', 'greeting', 'greeting', 'changename', 'changename', 'changename', 'menu']\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 2 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 5 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 4 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "accurary:  0.7428571428571429\n",
      "f1_score:  0.7328385899814471\n",
      "precision:  0.8442857142857143\n",
      "recall:  0.7428571428571429\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of intent matching with correct English\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import csv\n",
    "# Read question-answer pair in csv file\n",
    "with open('ExperimentQuestions.csv', mode='r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    corpus = list(reader)\n",
    "    \n",
    "with open('intent.json', encoding='utf-8') as file:\n",
    "    data1 = json.load(file)\n",
    "        \n",
    "corpus = [sentence for sublist in corpus for sentence in sublist]\n",
    "prediction = []\n",
    "label = [\"greeting\", \"greeting\", \"greeting\", \"greeting\", \"greeting\", \"greeting\", \"smalltalk\", \"formalgreeting\", \"formalgreeting\", \"help\", \"username\", \"chatbot\", \"chatbot\",\n",
    "         \"help\", \"americano\", \"mocha\", \"coffee bean\", \"espresso price\", \"recommendation\", \"latte\", \"decaf\",\"menu\", \"menu\", \"transaction\", \"transaction\", \"transaction\", \n",
    "         \"transaction\", \"transaction\", \"transaction\", \"changename\", \"changename\", \"changename\", \"changename\", \"changename\", \"changename\"]\n",
    "\n",
    "max_len = 20\n",
    "\n",
    "model1, lbl_encoder1, tokenizer1 = model(data1)\n",
    "\n",
    "for sentence in corpus:\n",
    "    query = sentence\n",
    "    result = model1.predict(pad_sequences(tokenizer1.texts_to_sequences([query]), truncating='post', maxlen=max_len), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "    tag = lbl_encoder1.inverse_transform([np.argmax(result)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "\n",
    "    for i in data1['intents']:\n",
    "        if i['tag'] == tag:\n",
    "            prediction.append(tag[0])\n",
    "\n",
    "# prediction = prediction.tolist()\n",
    "print(label)\n",
    "print('\\n')\n",
    "print(prediction)\n",
    "\n",
    "#Print confusion matrix, accuracy, and f1 score\n",
    "print(confusion_matrix(label, prediction))\n",
    "print(\"accurary: \", accuracy_score(label, prediction))\n",
    "print(\"f1_score: \", f1_score(label, prediction, average='weighted'))\n",
    "print(\"precision: \", precision_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "print(\"recall: \", recall_score(label, prediction, average = 'weighted', zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9baaa5-804c-404d-8d29-458db8645d9d",
   "metadata": {},
   "source": [
    "## Evaluation of intent matching with misspelled words and incorrect grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a05513f-a766-4f0e-879e-fae8280e7f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'smalltalk', 'formalgreeting', 'formalgreeting', 'help', 'username', 'chatbot', 'chatbot', 'help', 'cappuccino', 'latte', 'coffee bean', 'espresso price', 'recommendation', 'latte', 'decaf', 'menu', 'menu', 'transaction', 'transaction', 'transaction', 'transaction', 'transaction', 'transaction', 'changename', 'changename', 'changename', 'changename', 'changename', 'changename']\n",
      "\n",
      "\n",
      "['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'menu', 'smalltalk', 'greeting', 'greeting', 'help', 'username', 'chatbot', 'chatbot', 'menu', 'americano', 'transaction', 'coffee bean', 'mocha price', 'recommendation', 'transaction', 'decaf', 'menu', 'menu', 'transaction', 'transaction', 'transaction', 'transaction', 'menu', 'greeting', 'greeting', 'greeting', 'username', 'changename', 'changename', 'changename']\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 2 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 5 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 4 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "0.6285714285714286\n",
      "0.596938775510204\n",
      "0.8085714285714286\n",
      "0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of intent matching with misspelled words and incorrect grammar\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import csv\n",
    "# Read question-answer pair in csv file\n",
    "with open('ExperimentQuestions_With_Incorrect_English.csv', mode='r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    corpus = list(reader)\n",
    "    \n",
    "with open('intent.json', encoding='utf-8') as file:\n",
    "    data1 = json.load(file)\n",
    "\n",
    "corpus = [sentence for sublist in corpus for sentence in sublist]\n",
    "prediction = []\n",
    "label = [\"greeting\", \"greeting\", \"greeting\", \"greeting\", \"greeting\", \"greeting\", \"smalltalk\", \"formalgreeting\", \"formalgreeting\", \"help\", \"username\", \"chatbot\", \n",
    "         \"chatbot\", \"help\", \"cappuccino\", \"latte\", \"coffee bean\", \"espresso price\", \"recommendation\", \"latte\", \"decaf\",\"menu\", \"menu\", \"transaction\", \"transaction\",\n",
    "         \"transaction\", \"transaction\", \"transaction\", \"transaction\", \"changename\", \"changename\", \"changename\", \"changename\", \"changename\", \"changename\"]\n",
    "\n",
    "max_len = 20\n",
    "\n",
    "model1, lbl_encoder1, tokenizer1 = model(data1)\n",
    "\n",
    "for sentence in corpus:\n",
    "    query = sentence\n",
    "    result = model1.predict(pad_sequences(tokenizer1.texts_to_sequences([query]), truncating='post', maxlen=max_len), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "    tag = lbl_encoder1.inverse_transform([np.argmax(result)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "\n",
    "    for i in data1['intents']:\n",
    "        if i['tag'] == tag:\n",
    "            prediction.append(tag[0])\n",
    "\n",
    "# prediction = prediction.tolist()\n",
    "print(label)\n",
    "print('\\n')\n",
    "print(prediction)\n",
    "\n",
    "#Print confusion matrix, accuracy, and f1 score\n",
    "print(confusion_matrix(label, prediction))\n",
    "print(accuracy_score(label, prediction))\n",
    "print(f1_score(label, prediction, average='weighted'))\n",
    "print(precision_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "print(recall_score(label, prediction, average = 'weighted', zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f0023-f3ad-43a8-b962-ce8cbad54d2f",
   "metadata": {},
   "source": [
    "## Evaluation of sentiment analysis for feedback and user confirmation during beverage ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23cf2c09-9f4e-4166-a469-3ad2c481882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n",
      "['negative']\n",
      "['negative']\n",
      "['positive']\n",
      "['positive']\n",
      "['negative']\n",
      "['positive']\n",
      "['positive']\n",
      "['positive']\n",
      "['negative']\n",
      "['positive']\n",
      "['positive']\n",
      "['negative']\n",
      "['positive']\n",
      "['negative']\n",
      "['negative']\n",
      "['positive']\n",
      "['positive']\n",
      "['positive']\n",
      "['positive']\n",
      "['negative']\n",
      "['positive']\n",
      "['positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive']\n",
      "[[ 7  4]\n",
      " [ 1 10]]\n",
      "0.7727272727272727\n",
      "0.768421052631579\n",
      "0.7946428571428572\n",
      "0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of sentiment analysis for feedback and user confirmation during beverage ordering\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "with open('PositiveNegativeData.json', encoding='utf-8') as file1:\n",
    "    data2 = json.load(file1)\n",
    "\n",
    "corpus = [\"That was very helpful, thank you!\",\n",
    "          \"I didn't quite understand your response.\",\n",
    "          \"Your chatbot needs improvement in understanding natural language.\",\n",
    "          \"Your chatbot is doing a great job at answering my questions!\",\n",
    "          \"That was a quick and accurate response, good job!\",\n",
    "          \"I'm not satisfied with your chatbot's response, can you provide more information?\",\n",
    "          \"Your chatbot is very informative and easy to use.\",\n",
    "          \"I think your chatbot misunderstood my question, can you clarify?\",\n",
    "          \"Your chatbot is well-performed, thanks!\",\n",
    "          \"The chatbot's response was a bit too vague, can you provide more detail?\",\n",
    "          \"good\",\n",
    "          \"bad\",\n",
    "          \"I think there's been a mistake. I ordered a latte, but I received a cappuccino instead.\",\n",
    "          \"Excuse me, but this isn't what I ordered.\",\n",
    "          \"I'm sorry, but this isn't the coffee I requested.\",\n",
    "          \"My order seems to be incorrect.\",\n",
    "          \"This isn't what I ordered.\",\n",
    "          \"Alright, everything looks good.\",\n",
    "          \"Yes, I confirm my order.\",\n",
    "          \"Perfect, that's what I ordered.\",\n",
    "          \"That's right, thank you.\",\n",
    "          \"Yes, that's correct.\"]\n",
    "\n",
    "label = [\"positive\", \"negative\", \"negative\", \"positive\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"negative\", \n",
    "         \"negative\", \"negative\", \"negative\", \"negative\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\"]\n",
    "\n",
    "prediction = []\n",
    "\n",
    "model2, lbl_encoder2, tokenizer2 = model(data2)\n",
    "\n",
    "for query in corpus:\n",
    "    flag = feedback(query, model2, tokenizer2, lbl_encoder2)\n",
    "\n",
    "    if(flag==True):\n",
    "        prediction.append(\"positive\")\n",
    "    else:\n",
    "        prediction.append(\"negative\")\n",
    "\n",
    "print(label)\n",
    "print(prediction)\n",
    "#Print confusion matrix, accuracy, f1 score, precision, and recall\n",
    "print(confusion_matrix(label, prediction))\n",
    "print(accuracy_score(label, prediction))\n",
    "print(f1_score(label, prediction, average='weighted'))\n",
    "print(precision_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "print(recall_score(label, prediction, average = 'weighted', zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b46f38-1917-44fc-991d-c6c18e93e6ce",
   "metadata": {},
   "source": [
    "## Evaluation of intent matching when having contextual queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff04e248-0784-4c3e-8887-fe8ff85edcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['americano price', 'transaction', 'transaction', 'transaction', 'username']\n",
      "\n",
      "\n",
      "['mocha price', 'transaction', 'transaction', 'transaction', 'username']\n",
      "[[0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 1]]\n",
      "accurary:  0.8\n",
      "f1_score:  0.8\n",
      "precision:  1.0\n",
      "recall:  0.8\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of intent matching when user refer to what they talked before (intent accurate does not mean the response is correct)\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "import csv\n",
    "    \n",
    "with open('intent.json', encoding='utf-8') as file:\n",
    "    data1 = json.load(file)\n",
    "    \n",
    "corpus = [\"What is Americano\", \"How much is it\", \n",
    "          \"How much is decaf coffee\", \"Can i have one of it\", \n",
    "          \"What is Mocha?\", \"Can I have one of it\",\n",
    "          \"What is flat white\", \"Please give me one of it and one black tea\", \n",
    "          \"My name is Hong Shen\", \"What is my name\"]\n",
    "\n",
    "label1 = [\"americano\", \"americano price\", \"decaf\", \"transaction\", \"mocha\", \"transaction\", \"flat white\", \"transaction\", \"changename\", \"username\"]\n",
    "label = [\"americano price\", \"transaction\", \"transaction\", \"transaction\", \"username\"]\n",
    "\n",
    "prediction = []\n",
    "predicted = []\n",
    "max_len = 20\n",
    "\n",
    "model1, lbl_encoder1, tokenizer1 = model(data1)\n",
    "\n",
    "for sentence in corpus:\n",
    "    query = sentence\n",
    "    result = model1.predict(pad_sequences(tokenizer1.texts_to_sequences([query]), truncating='post', maxlen=max_len), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "    tag = lbl_encoder1.inverse_transform([np.argmax(result)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "\n",
    "    for i in data1['intents']:\n",
    "        if i['tag'] == tag:\n",
    "            predicted.append(tag[0])\n",
    "\n",
    "prediction = [predicted[i] for i in range(1, len(predicted), 2)]\n",
    "\n",
    "# prediction = prediction.tolist()\n",
    "print(label)\n",
    "print('\\n')\n",
    "print(prediction)\n",
    "\n",
    "#Print confusion matrix, accuracy, and f1 score\n",
    "print(confusion_matrix(label, prediction))\n",
    "print(\"accurary: \", accuracy_score(label, prediction))\n",
    "print(\"f1_score: \", f1_score(label, prediction, average='weighted'))\n",
    "print(\"precision: \", precision_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "print(\"recall: \", recall_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f56af3-25fe-4c06-92e3-5a111ed0917d",
   "metadata": {},
   "source": [
    "## Average chatbot response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56cc537e-499c-40d7-9351-1281e17edfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Groovy:\n",
      " Hi\n",
      "Response time:  0.2821\n",
      "\n",
      "Groovy:\n",
      " Hi\n",
      "Response time:  0.0333\n",
      "\n",
      "Groovy:\n",
      " Hello\n",
      "Response time:  0.0371\n",
      "\n",
      "Groovy:\n",
      " Hey\n",
      "Response time:  0.0301\n",
      "\n",
      "Groovy:\n",
      " Hey\n",
      "Response time:  0.0448\n",
      "\n",
      "Groovy:\n",
      " It is highly depend on your taste of bitterness, sweetness and amount of milk. You can ask about the coffee or tea served in our menu to have an idea of their taste. However, the most popular coffee is cappuccino.\n",
      "Response time:  0.0356\n",
      "\n",
      "Groovy:\n",
      " I am fine, thanks for asking.\n",
      "Response time:  0.0385\n",
      "\n",
      "Groovy:\n",
      " Good day!\n",
      "Response time:  0.0373\n",
      "\n",
      "Groovy:\n",
      " Good day!\n",
      "Response time:  0.0321\n",
      "\n",
      "Groovy:\n",
      " I can have a small talk, help to take order and answer some questions regarding the beverages!\n",
      "Response time:  0.0482\n",
      "\n",
      "Groovy:\n",
      "Your name is Replace Sugesh Garnessan.\n",
      "Response time:  0.0424\n",
      "\n",
      "Groovy:\n",
      "Noted, your name is .\n",
      "Response time:  0.032\n",
      "\n",
      "Groovy:\n",
      " I'm Groovy, an Artificial Intelligent bot\n",
      "Response time:  0.0439\n",
      "\n",
      "\n",
      "Menu:\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Espresso\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Americano\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Cappuccino\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Latte\t\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Macchiato\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Flat White\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Mocha\t\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Black Tea\t\t(£1.50)\n",
      "\n",
      "Response time:  0.0353\n",
      "\n",
      "Groovy:\n",
      " Americano also called as black coffee. It is simply just hot water and espresso. It will be served half espresso to half water.\n",
      "Response time:  0.0302\n",
      "Please confirm your order\n",
      "Thank you, your order has been confirmed\n",
      "Response time:  0.0406\n",
      "\n",
      "Groovy:\n",
      " We are using Arabica here.\n",
      "Response time:  0.0333\n",
      "\n",
      "Groovy:\n",
      " A cup of Espresso is £1.50\n",
      "Response time:  0.0318\n",
      "\n",
      "Groovy:\n",
      " It is highly depend on your taste of bitterness, sweetness and amount of milk. You can ask about the coffee or tea served in our menu to have an idea of their taste. However, the most popular coffee is cappuccino.\n",
      "Response time:  0.0302\n",
      "\n",
      "Groovy:\n",
      " A cup of Cappuccino is £1.80\n",
      "Response time:  0.0415\n",
      "\n",
      "Groovy:\n",
      " Decaf is short for decaffeinated coffee, it has at least 97% of caffeine removed. Unfortunately, we do not sell decaf coffee, sorry for any inconvenience.\n",
      "Response time:  0.0302\n",
      "\n",
      "\n",
      "Menu:\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Espresso\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Americano\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Cappuccino\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Latte\t\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Macchiato\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Flat White\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Mocha\t\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Black Tea\t\t(£1.50)\n",
      "\n",
      "Response time:  0.0403\n",
      "\n",
      "\n",
      "Menu:\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Espresso\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Americano\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Cappuccino\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Latte\t\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Macchiato\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Flat White\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Mocha\t\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Black Tea\t\t(£1.50)\n",
      "\n",
      "Response time:  0.0322\n",
      "Please confirm your order\n",
      "Thank you, your order has been confirmed\n",
      "Response time:  0.0302\n",
      "Please confirm your order\n",
      "Thank you, your order has been confirmed\n",
      "Response time:  0.0453\n",
      "Please confirm your order\n",
      "Thank you, your order has been confirmed\n",
      "Response time:  0.0382\n",
      "\n",
      "Groovy:\n",
      " Decaf is short for decaffeinated coffee, it has at least 97% of caffeine removed. Unfortunately, we do not sell decaf coffee, sorry for any inconvenience.\n",
      "Response time:  0.0362\n",
      "\n",
      "Groovy:\n",
      " My pleasure\n",
      "Response time:  0.0305\n",
      "\n",
      "Groovy:\n",
      " Any time!\n",
      "Response time:  0.0311\n",
      "\n",
      "Groovy:\n",
      " Hi\n",
      "Response time:  0.0392\n",
      "\n",
      "Groovy:\n",
      " Hi\n",
      "Response time:  0.0352\n",
      "\n",
      "Groovy:\n",
      "Your name is .\n",
      "Response time:  0.0358\n",
      "\n",
      "Groovy:\n",
      "Noted, your name is Hong Shen.\n",
      "Response time:  0.0309\n",
      "\n",
      "Groovy:\n",
      "Your name is Hong Shen.\n",
      "Response time:  0.0403\n",
      "\n",
      "Groovy:\n",
      "Your name is Hong Shen.\n",
      "Response time:  0.0303\n",
      "[0.2821, 0.0333, 0.0371, 0.0301, 0.0448, 0.0356, 0.0385, 0.0373, 0.0321, 0.0482, 0.0424, 0.032, 0.0439, 0.0353, 0.0302, 0.0406, 0.0333, 0.0318, 0.0302, 0.0415, 0.0302, 0.0403, 0.0322, 0.0302, 0.0453, 0.0382, 0.0362, 0.0305, 0.0311, 0.0392, 0.0352, 0.0358, 0.0309, 0.0403, 0.0303]\n",
      "['positive']\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.2632\n",
      "['negative']\n",
      "\n",
      "Groovy:\n",
      "I am sorry to hear that, I will feedback to my company.\n",
      "Bye, take care Hong Shen\n",
      "Response time:  0.0403\n",
      "['negative']\n",
      "\n",
      "Groovy:\n",
      "I am sorry to hear that, I will feedback to my company.\n",
      "Bye, take care Hong Shen\n",
      "Response time:  0.0376\n",
      "['positive']\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.0379\n",
      "['positive']\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.0371\n",
      "['negative']\n",
      "\n",
      "Groovy:\n",
      "I am sorry to hear that, I will feedback to my company.\n",
      "Bye, take care Hong Shen\n",
      "Response time:  0.0403\n",
      "['positive']\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.042\n",
      "['positive']\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.0326\n",
      "['positive']\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.0371\n",
      "['positive']\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.0381\n",
      "\n",
      "Total response:  45\n",
      "\n",
      " [0.2821, 0.0333, 0.0371, 0.0301, 0.0448, 0.0356, 0.0385, 0.0373, 0.0321, 0.0482, 0.0424, 0.032, 0.0439, 0.0353, 0.0302, 0.0406, 0.0333, 0.0318, 0.0302, 0.0415, 0.0302, 0.0403, 0.0322, 0.0302, 0.0453, 0.0382, 0.0362, 0.0305, 0.0311, 0.0392, 0.0352, 0.0358, 0.0309, 0.0403, 0.0303, 0.2632, 0.0403, 0.0376, 0.0379, 0.0371, 0.0403, 0.042, 0.0326, 0.0371, 0.0381]\n",
      "\n",
      "Average response time:  0.046942222222222225\n"
     ]
    }
   ],
   "source": [
    "# Calculate avergae chatbot response time\n",
    "import time\n",
    "import statistics\n",
    "import csv\n",
    "# Read question-answer pair in csv file\n",
    "with open('ExperimentQuestions.csv', mode='r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    corpus = list(reader)\n",
    "    \n",
    "with open('intent.json', encoding='utf-8') as file:\n",
    "    data1 = json.load(file)\n",
    "    \n",
    "with open('PositiveNegativeData.json', encoding='utf-8') as file1:\n",
    "    data2 = json.load(file1)\n",
    "        \n",
    "corpus = [sentence for sublist in corpus for sentence in sublist]\n",
    "\n",
    "max_len = 20\n",
    "\n",
    "model1, lbl_encoder1, tokenizer1 = model(data1)\n",
    "model2, lbl_encoder2, tokenizer2 = model(data2)\n",
    "\n",
    "queryList = [\"\",\"\"]\n",
    "response_time = []\n",
    "for sentence in corpus:\n",
    "    query = sentence\n",
    "    queryList[0] = queryList[1]\n",
    "    queryList[1] = query.lower()\n",
    "    start_time = time.time()\n",
    "    result = model1.predict(pad_sequences(tokenizer1.texts_to_sequences([query]), truncating='post', maxlen=max_len), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "    tag = lbl_encoder1.inverse_transform([np.argmax(result)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "\n",
    "    for i in data1['intents']:\n",
    "        if i['tag'] == tag:\n",
    "            # prediction.append(tag[0])\n",
    "            response = np.random.choice(i['responses'])\n",
    "            if response == \"Menu\":\n",
    "                openMenu()                  \n",
    "            elif response == \"transaction\":\n",
    "                print(\"Please confirm your order\")\n",
    "                print(\"Thank you, your order has been confirmed\")\n",
    "            elif response == \"username\":\n",
    "                print(\"\\nGroovy:\\nYour name is\" + (newName if len(newName)!= 0 else name) + \".\")\n",
    "            elif response == \"Change name\":\n",
    "                newName = NER(query)\n",
    "                print(\"\\nGroovy:\\nNoted, your name is\" + (newName if len(newName)!= 0 else name) + \".\")\n",
    "            else:\n",
    "                print(\"\\nGroovy:\\n\", response)\n",
    "            end_time = time.time()\n",
    "            response_time.append(round(end_time - start_time, 4)) # calculate response time\n",
    "            print(\"Response time: \", response_time[-1])\n",
    "print(response_time)\n",
    "\n",
    "# sentiment analysis response time\n",
    "corpus = [\"That was very helpful, thank you!\",\n",
    "          \"I didn't quite understand your response.\",\n",
    "          \"Your chatbot needs improvement in understanding natural language.\",\n",
    "          \"Your chatbot is doing a great job at answering my questions!\",\n",
    "          \"That was a quick and accurate response, good job!\",\n",
    "          \"I'm not satisfied with your chatbot's response, can you provide more information?\",\n",
    "          \"Your chatbot is very informative and easy to use.\",\n",
    "          \"I think your chatbot misunderstood my question, can you clarify?\",\n",
    "          \"good\",\n",
    "          \"bad\"]\n",
    "\n",
    "for query in corpus:\n",
    "    start_time = time.time()\n",
    "    prediction = feedback(query, model2, tokenizer2, lbl_encoder2)\n",
    "    if(prediction==True):\n",
    "        print('\\nGroovy:\\nThank you for your feedback, I am glad to hear that!')\n",
    "    else:\n",
    "        print('\\nGroovy:\\nI am sorry to hear that, I will feedback to my company.')\n",
    "        print(\"Bye, take care\"+ (newName if len(newName)!=0 else name))\n",
    "    end_time = time.time()\n",
    "    response_time.append(round(end_time - start_time, 4)) # calculate response time\n",
    "    print(\"Response time: \", response_time[-1])\n",
    "\n",
    "print(\"\\nTotal response: \",len(response_time))\n",
    "print(\"\\n\",response_time)\n",
    "\n",
    "# calculate average response time\n",
    "avg_response_time = statistics.mean(response_time)\n",
    "print(\"\\nAverage response time: \", avg_response_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be0483-c03c-4194-83e3-1f4a56d1d2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
