{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0043c7-3ded-43d8-b36f-79070770437c",
   "metadata": {},
   "source": [
    "# Machine Learning Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c69a93-2969-411c-b599-03c9c8ae7716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in d:\\ananconda\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: python-Levenshtein in d:\\ananconda\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: Levenshtein==0.21.0 in d:\\ananconda\\lib\\site-packages (from python-Levenshtein) (0.21.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in d:\\ananconda\\lib\\site-packages (from Levenshtein==0.21.0->python-Levenshtein) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference:\n",
    "# **********************************************************************************************************\n",
    "#    Title: Build Your Own Chatbot Using Deep Learning\n",
    "#    Author: Sreekanth\n",
    "#    Date: Oct 17, 2021\n",
    "#    Availability: https://medium.com/@rr_42830/build-your-own-chatbot-using-deep-learning-23a022638067\n",
    "#\n",
    "# **********************************************************************************************************\n",
    "!pip install fuzzywuzzy\n",
    "!pip install python-Levenshtein\n",
    "\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d4c17e-2c83-47ee-ab53-9f17dba8b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and modelling\n",
    "def model(data):\n",
    "    # extract data from json file\n",
    "    training_sentences = []\n",
    "    training_labels = []\n",
    "    labels = []\n",
    "    responses = []\n",
    "\n",
    "\n",
    "    for intent in data['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            training_sentences.append(pattern)\n",
    "            training_labels.append(intent['tag'])\n",
    "        responses.append(intent['responses'])\n",
    "\n",
    "        if intent['tag'] not in labels:\n",
    "            labels.append(intent['tag'])\n",
    "\n",
    "    num_classes = len(labels)\n",
    "\n",
    "    # one hot encoding\n",
    "    lbl_encoder = LabelEncoder() # convert categorical variables to numerical labels (\"greeting\", \"bye\", \"thanks\") -> (0, 1, 2)\n",
    "    lbl_encoder.fit(training_labels) \n",
    "    training_labels = lbl_encoder.transform(training_labels)\n",
    "    training_labels = keras.utils.to_categorical(training_labels, num_classes=num_classes)\n",
    "\n",
    "    vocab_size = 1000\n",
    "    embedding_dim = 20\n",
    "    max_len = 20\n",
    "    oov_token = \"<OOV>\" # out of vocabulary token value\n",
    "\n",
    "    # tokenizing text, converting words to lowercase, filtering out punctuation, and converting text into sequences of integers\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token) \n",
    "    tokenizer.fit_on_texts(training_sentences)\n",
    "    word_index = tokenizer.word_index\n",
    "    sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "    padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)\n",
    "    \n",
    "    train_data = padded_sequences\n",
    "    train_labels = training_labels\n",
    "    \n",
    "    # LSTM model\n",
    "    model = keras.Sequential([\n",
    "        Embedding(len(word_index)+1, embedding_dim, input_length=max_len),\n",
    "        LSTM(embedding_dim),\n",
    "        Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.fit(train_data, train_labels, epochs=150, verbose=0)\n",
    "    \n",
    "    return model, lbl_encoder, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f84d03-34ac-479b-a8f7-450f38d48a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openMenu():\n",
    "    with open('Beverage_Menu.txt', 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "621e59da-b668-46f3-ab8a-81f5251b660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name Entity Recognision (NER)\n",
    "def NER(query):\n",
    "    name_entity = []\n",
    "    words =  nltk.word_tokenize(query)\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    chunked = nltk.ne_chunk(tagged, binary=False)\n",
    "    for chunk in chunked.leaves():\n",
    "        if hasattr(chunk, 'label') or chunk[1] == 'NNP':\n",
    "            name_entity.append(chunk[0])\n",
    "                \n",
    "    userName = ' ' + ' '.join(name for name in name_entity)\n",
    "    return userName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a052994-5970-48a4-b5a1-16680e738c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectBeverage(query, menuPrice):\n",
    "    from fuzzywuzzy import fuzz\n",
    "    \n",
    "    matching_items = []\n",
    "    query = query.lower().split()\n",
    "    for word in query:\n",
    "        for item in menuPrice.keys():\n",
    "            match_score = fuzz.token_set_ratio(word, item.lower()) # Calculate fuzzy match score between user query and coffee item\n",
    "            if match_score > 80:\n",
    "                if item not in matching_items:\n",
    "                    matching_items.append(item.title())\n",
    "    return matching_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c2120f-f5d1-496b-b0d1-6747e0b5c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect number in user query\n",
    "def detectNumber(query):\n",
    "    num_dict = {\"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\":6, \"seven\":7, \"eight\":8, \"nine\":9, \"ten\":10} # number dictionary\n",
    "    \n",
    "    quantity = []\n",
    "    for word in query.split():\n",
    "        if word.isdigit():\n",
    "            quantity += [int(word)]\n",
    "        else:\n",
    "            for w in num_dict:\n",
    "                if w == word:\n",
    "                    quantity += [num_dict[word]]\n",
    "    return quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e81697-6b43-4430-8778-6fc37e01cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction function\n",
    "\n",
    "def transaction(queryList, model2, tokenizer2, lbl_encoder2):\n",
    "     \n",
    "    menuPrice = {\"Espresso\": 1.50, \"Americano\": 1.50, \"Cappuccino\": 1.80, \"Latte\": 1.80, \"Macchiato\": 1.80, \"Flat White\": 2.10, \"Mocha\": 2.10, \"Black Tea\": 1.50}\n",
    "\n",
    "    lastQuery = queryList[0]\n",
    "    currentQuery = queryList[1]\n",
    "    \n",
    "    switch = True    \n",
    "    while switch == True:\n",
    "        # Detect quantity in user query\n",
    "        temp_query = currentQuery\n",
    "        quantity = detectNumber(temp_query)        \n",
    "        \n",
    "        # Detect beverage\n",
    "        beverages = detectBeverage(currentQuery, menuPrice)\n",
    "        if len(beverages) == 0:\n",
    "            beverages = detectBeverage(lastQuery, menuPrice)\n",
    "        \n",
    "        if len(beverages) == 0:\n",
    "            print('\\nSorry, your order does not appear in our menu.')\n",
    "            return True\n",
    "        \n",
    "        # Assume 1 for all beverage if no number detected\n",
    "        if(len(quantity) == 0):\n",
    "            for i in beverages:\n",
    "                quantity += [1]   \n",
    "    \n",
    "        if len(quantity)!=0 and len(quantity) == len(beverages):\n",
    "            # Find price of each beverage\n",
    "            price = []\n",
    "            for i, j in menuPrice.items():\n",
    "                for k in beverages:\n",
    "                    if k == i:\n",
    "                        price += [j]\n",
    "\n",
    "            #Calculate total price\n",
    "            totalPrice = sum([p*q for p, q in zip(price, quantity)])\n",
    "\n",
    "            print(\"\\n{:<10} {:<15} {:<10}\".format('Quantity', 'Beverage', 'Price'))\n",
    "            print(\"----------------------------------\\n\")\n",
    "            for i in range(len(price)):\n",
    "                print(\"{:<10} {:<15} £{:<10.2f}\".format(quantity[i], beverages[i], price[i]))\n",
    "            print('\\nTotal price is: £', \"{:.2f}\".format(totalPrice))\n",
    "            flag = True\n",
    "            while(flag == True):\n",
    "                print('\\nGroovy:\\nGreat! Please confirm your item, quantity and total price (e.g. yes/no). If you want to exit transaction, type quit. :')\n",
    "                confirmation = input().lower()\n",
    "                prediction = model2.predict(pad_sequences(tokenizer2.texts_to_sequences([confirmation]), truncating='post', maxlen=20), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "                tag = lbl_encoder2.inverse_transform([np.argmax(prediction)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "                if ('quit' in confirmation):\n",
    "                    flag = False\n",
    "                    return False\n",
    "                elif(tag == \"positive\"):\n",
    "                    flag = False\n",
    "                    print(\"\\nThank you! Your order has been confirmed.\")\n",
    "                    return False\n",
    "                else:\n",
    "                    print('\\nWould you like to reorder?')\n",
    "                    reorder_query = input(\"\\nUser:\\n\")\n",
    "                    returnFlag = feedback(reorder_query, model2, tokenizer2, lbl_encoder2)\n",
    "                    flag = False\n",
    "                    return returnFlag\n",
    "                           \n",
    "            switch = False\n",
    "        else:\n",
    "            print(\"Groovy:\\nPlease specify the quantity of each item (e.g. 2 mocha and 1 americano). If you want to exit transaction, type quit.\")\n",
    "            query = input(\"\\nUser:\\n\").lower()\n",
    "            if \"quit\" in query:\n",
    "                return False\n",
    "            else:\n",
    "                lastQuery = currentQuery\n",
    "                currentQuery = query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63726539-c922-4049-b2c6-18cb54d1f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback(query, model2, tokenizer2, lbl_encoder2):\n",
    "    prediction = model2.predict(pad_sequences(tokenizer2.texts_to_sequences([query]), truncating='post', maxlen=20), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "    tag = lbl_encoder2.inverse_transform([np.argmax(prediction)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "    if (tag == \"positive\"):\n",
    "        returnFlag = True\n",
    "        return returnFlag\n",
    "    elif (tag == \"negative\"):\n",
    "        returnFlag = False\n",
    "        return returnFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4df368fb-20f1-4e78-a8ad-63b60f6a79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def chat():\n",
    "    with open('intent.json', encoding='utf-8') as file:\n",
    "        data1 = json.load(file)\n",
    "        \n",
    "    with open('PositiveNegativeData.json', encoding='utf-8') as file1:\n",
    "        data2 = json.load(file1)\n",
    "    \n",
    "    model1, lbl_encoder1, tokenizer1 = model(data1)\n",
    "    model2, lbl_encoder2, tokenizer2 = model(data2)\n",
    "    \n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    queryList = [\"\",\"\"]\n",
    "    newName = \"\"\n",
    "    flag1 = True\n",
    "    flag2 = False\n",
    "    print(\"Groovy:\\nHello, welcome to Chin's Coffee House! What is your name?\")\n",
    "    query = input(\"\\nUser:\\n\")\n",
    "    name = NER(query)\n",
    "    while flag1:\n",
    "        if flag2 == True:\n",
    "            print('\\nGroovy:\\nWhat would you like to order? If you want to exit, type quit.')\n",
    "            query = input(\"\\nUser:\\n\")\n",
    "            flag2 = False\n",
    "        else:\n",
    "            print('\\nGroovy:\\nHi'+ (newName if len(newName)!=0 else name) +\". Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\")\n",
    "            query = input(\"\\nUser:\\n\")\n",
    "            \n",
    "        if query.lower() == \"quit\":\n",
    "            flag1 = False\n",
    "            print(\"\\nGroovy:\\nThank you for visiting Chin's Coffee House. What do you think of my service?\")\n",
    "            query = input(\"\\nUser:\\n\")\n",
    "            prediction = feedback(query, model2, tokenizer2, lbl_encoder2)\n",
    "            if(prediction==True):\n",
    "                print('\\nGroovy:\\nThank you for your feedback, I am glad to hear that!')\n",
    "            else:\n",
    "                print('\\nGroovy:\\nI am sorry to hear that, I will feedback to my company.')\n",
    "            print(\"Bye, take care\"+ (newName if len(newName)!=0 else name))\n",
    "        else:\n",
    "            queryList[0] = queryList[1]\n",
    "            queryList[1] = query.lower()\n",
    "            \n",
    "            result = model1.predict(pad_sequences(tokenizer1.texts_to_sequences([query]), truncating='post', maxlen=max_len), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "            tag = lbl_encoder1.inverse_transform([np.argmax(result)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "\n",
    "            for i in data1['intents']:\n",
    "                if i['tag'] == tag:\n",
    "                    response = np.random.choice(i['responses'])\n",
    "                    if response == \"Menu\":\n",
    "                        openMenu()                  \n",
    "                        flag2 = True\n",
    "                    elif response == \"transaction\":\n",
    "                        flag2 = transaction(queryList, model2, tokenizer2, lbl_encoder2)\n",
    "                    elif response == \"username\":\n",
    "                        print(\"\\nGroovy:\\nYour name is\" + (newName if len(newName)!= 0 else name) + \".\")\n",
    "                    elif response == \"Change name\":\n",
    "                        newName = NER(query)\n",
    "                        print(\"\\nGroovy:\\nNoted, your name is\" + (newName if len(newName)!= 0 else name) + \".\")\n",
    "                    else:\n",
    "                        print(\"\\nGroovy:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02fb902-3381-4e07-9701-2bd53ef02fe1",
   "metadata": {},
   "source": [
    "## Run machine-learning chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c30f7863-4268-4302-9bbb-c6c9bd33faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groovy:\n",
      "Hello, welcome to Chin's Coffee House! What is your name?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " John\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Groovy:\n",
      "Hi John. Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " what is my name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Groovy:\n",
      "Your name is John.\n",
      "\n",
      "Groovy:\n",
      "Hi John. Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " what is mocha\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Groovy:\n",
      " Mocha is a shot of espresso is combined with a chocolate powder or syrup, followed by milk or cream.\n",
      "\n",
      "Groovy:\n",
      "Hi John. Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " can i have one of it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantity   Beverage        Price     \n",
      "----------------------------------\n",
      "\n",
      "1          Mocha           £2.10      \n",
      "\n",
      "Total price is: £ 2.10\n",
      "\n",
      "Groovy:\n",
      "Great! Please confirm your item, quantity and total price (e.g. yes/no). If you want to exit transaction, type quit. :\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " correct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you! Your order has been confirmed.\n",
      "\n",
      "Groovy:\n",
      "Hi John. Welcome to Chin's Coffee House. How can I help you? If you want to exit, type quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Groovy:\n",
      "Thank you for visiting Chin's Coffee House. What do you think of my service?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:\n",
      " nice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Bye, take care John\n"
     ]
    }
   ],
   "source": [
    "# Run machine-learning chatbot\n",
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be49884d-99c9-40c7-8e8c-33e7ee94dfa8",
   "metadata": {},
   "source": [
    "# Experiments: Machine Learning Chatbot Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be8fa3-bd2c-4474-b188-9a5a09d0e4b6",
   "metadata": {},
   "source": [
    "## Evaluation of intent matching with correct English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ea9039-e188-443f-9805-c60fc1697463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurary:  0.7628571428571429\n",
      "f1_score:  0.7727137624280481\n",
      "precision:  0.8848707482993197\n",
      "recall:  0.7628571428571429\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of intent matching with correct English\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "k = 0\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "while(k < 10):\n",
    "    # Read question-answer pair in csv file\n",
    "    with open('ExperimentQuestions.csv', mode='r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        corpus = list(reader)\n",
    "\n",
    "    with open('intent.json', encoding='utf-8') as file:\n",
    "        data1 = json.load(file)\n",
    "\n",
    "    corpus = [sentence for sublist in corpus for sentence in sublist]\n",
    "    prediction = []\n",
    "    label = [\"greeting\", \"greeting\", \"greeting\", \"greeting\", \"greeting\", \"greeting\", \"smalltalk\", \"formalgreeting\", \"formalgreeting\", \"help\", \"username\", \"chatbot\", \"chatbot\",\n",
    "             \"help\", \"americano\", \"mocha\", \"coffee bean\", \"espresso price\", \"recommendation\", \"latte\", \"decaf\",\"menu\", \"menu\", \"transaction\", \"transaction\", \"transaction\", \n",
    "             \"transaction\", \"transaction\", \"transaction\", \"changename\", \"changename\", \"changename\", \"changename\", \"changename\", \"changename\"]\n",
    "\n",
    "    max_len = 20\n",
    "\n",
    "    model1, lbl_encoder1, tokenizer1 = model(data1)\n",
    "\n",
    "    for sentence in corpus:\n",
    "        query = sentence\n",
    "        result = model1.predict(pad_sequences(tokenizer1.texts_to_sequences([query]), truncating='post', maxlen=max_len), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "        tag = lbl_encoder1.inverse_transform([np.argmax(result)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "\n",
    "        for i in data1['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                prediction.append(tag[0])\n",
    "    \n",
    "    accuracy_list.append(accuracy_score(label, prediction))\n",
    "    precision_list.append(precision_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "    recall_list.append(recall_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "    f1_list.append(f1_score(label, prediction, average='weighted'))\n",
    "    k = k+1\n",
    "\n",
    "    \n",
    "#Print accuracy, precision, recall and f1 score\n",
    "print(\"accurary: \", statistics.mean(accuracy_list))\n",
    "print(\"f1_score: \", statistics.mean(f1_list))\n",
    "print(\"precision: \", statistics.mean(precision_list))\n",
    "print(\"recall: \", statistics.mean(recall_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9baaa5-804c-404d-8d29-458db8645d9d",
   "metadata": {},
   "source": [
    "## Evaluation of intent matching with typo and grammatical error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a05513f-a766-4f0e-879e-fae8280e7f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurary:  0.6457142857142857\n",
      "f1_score:  0.6447829313543599\n",
      "precision:  0.8274557823129252\n",
      "recall:  0.6457142857142857\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of intent matching with misspelled words and incorrect grammar\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "k = 0\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "while(k < 10):\n",
    "    # Read question-answer pair in csv file\n",
    "    with open('ExperimentQuestions_With_Incorrect_English.csv', mode='r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        corpus = list(reader)\n",
    "\n",
    "    with open('intent.json', encoding='utf-8') as file:\n",
    "        data1 = json.load(file)\n",
    "\n",
    "    corpus = [sentence for sublist in corpus for sentence in sublist]\n",
    "    prediction = []\n",
    "    label = [\"greeting\", \"greeting\", \"greeting\", \"greeting\", \"greeting\", \"greeting\", \"smalltalk\", \"formalgreeting\", \"formalgreeting\", \"help\", \"username\", \"chatbot\", \n",
    "             \"chatbot\", \"help\", \"cappuccino\", \"latte\", \"coffee bean\", \"espresso price\", \"recommendation\", \"latte\", \"decaf\",\"menu\", \"menu\", \"transaction\", \"transaction\",\n",
    "             \"transaction\", \"transaction\", \"transaction\", \"transaction\", \"changename\", \"changename\", \"changename\", \"changename\", \"changename\", \"changename\"]\n",
    "\n",
    "    max_len = 20\n",
    "\n",
    "    model1, lbl_encoder1, tokenizer1 = model(data1)\n",
    "\n",
    "    for sentence in corpus:\n",
    "        query = sentence\n",
    "        result = model1.predict(pad_sequences(tokenizer1.texts_to_sequences([query]), truncating='post', maxlen=max_len), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "        tag = lbl_encoder1.inverse_transform([np.argmax(result)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "\n",
    "        for i in data1['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                prediction.append(tag[0])\n",
    "\n",
    "    accuracy_list.append(accuracy_score(label, prediction))\n",
    "    precision_list.append(precision_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "    recall_list.append(recall_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "    f1_list.append(f1_score(label, prediction, average='weighted'))\n",
    "    k = k+1\n",
    "    \n",
    "#Print accuracy, precision, recall and f1 score\n",
    "print(\"accurary: \", statistics.mean(accuracy_list))\n",
    "print(\"f1_score: \", statistics.mean(f1_list))\n",
    "print(\"precision: \", statistics.mean(precision_list))\n",
    "print(\"recall: \", statistics.mean(recall_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f0023-f3ad-43a8-b962-ce8cbad54d2f",
   "metadata": {},
   "source": [
    "## Evaluation of sentiment analysis for feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23cf2c09-9f4e-4166-a469-3ad2c481882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurary:  0.605\n",
      "f1_score:  0.5976233245673278\n",
      "precision:  0.6120751470751471\n",
      "recall:  0.605\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of sentiment analysis for feedback and user confirmation during beverage ordering\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import statistics\n",
    "\n",
    "k = 0\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "while(k < 10):\n",
    "    with open('PositiveNegativeData.json', encoding='utf-8') as file1:\n",
    "        data2 = json.load(file1)\n",
    "\n",
    "    corpus = [\"That was very helpful, thank you!\",\n",
    "              \"I didn't quite understand your response.\",\n",
    "              \"Your chatbot needs improvement in understanding natural language.\",\n",
    "              \"Your chatbot is doing a great job at answering my questions!\",\n",
    "              \"That was a quick and accurate response, good job!\",\n",
    "              \"I'm not satisfied with your chatbot's response, can you provide more information?\",\n",
    "              \"Your chatbot is very informative and easy to use.\",\n",
    "              \"I think your chatbot misunderstood my question, can you clarify?\",\n",
    "              \"Your chatbot is well-performed, thanks!\",\n",
    "              \"The chatbot's response was a bit too vague, can you provide more detail?\",\n",
    "              \"good\",\n",
    "              \"bad\", \n",
    "              \"I really enjoyed using your chatbot to order my drink. It was quick and easy to navigate.\", \n",
    "              \"Your chatbot was able to accurately understand my order and provide helpful suggestions. Great job!\", \n",
    "              \"I had a bit of trouble with the chatbot understanding my order. Maybe adding more prompts or options could help.\", \n",
    "              \"The chatbot seemed a bit slow and unresponsive at times, which was frustrating. Maybe there's a way to speed up the system?\", \n",
    "              \"The chatbot didn't seem to have all the drink options I was looking for. It would be great to see a wider selection in the future.\",\n",
    "              \"I appreciate that your chatbot gave me the option to customize my drink order. It made the experience feel more personalized.\", \n",
    "              \"The chatbot gave me an error message when trying to process my payment. It would be helpful to have clearer instructions or troubleshooting tips.\", \n",
    "              \"Overall, I had a positive experience using your chatbot to order my beverage. Thank you for making the process more convenient!\"]\n",
    "\n",
    "    label = [\"positive\", \"negative\", \"negative\", \"positive\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"positive\",\n",
    "             \"negative\", \"negative\", \"negative\", \"positive\", \"negative\", \"positive\"]\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    model2, lbl_encoder2, tokenizer2 = model(data2)\n",
    "\n",
    "    for query in corpus:\n",
    "        flag = feedback(query, model2, tokenizer2, lbl_encoder2)\n",
    "\n",
    "        if(flag==True):\n",
    "            prediction.append(\"positive\")\n",
    "        else:\n",
    "            prediction.append(\"negative\")\n",
    "\n",
    "    accuracy_list.append(accuracy_score(label, prediction))\n",
    "    precision_list.append(precision_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "    recall_list.append(recall_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "    f1_list.append(f1_score(label, prediction, average='weighted'))\n",
    "    k = k+1\n",
    "    \n",
    "#Print accuracy, precision, recall and f1 score\n",
    "print(\"accurary: \", statistics.mean(accuracy_list))\n",
    "print(\"f1_score: \", statistics.mean(f1_list))\n",
    "print(\"precision: \", statistics.mean(precision_list))\n",
    "print(\"recall: \", statistics.mean(recall_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b46f38-1917-44fc-991d-c6c18e93e6ce",
   "metadata": {},
   "source": [
    "## Evaluation of intent matching when having contextual queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff04e248-0784-4c3e-8887-fe8ff85edcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurary:  0.8200000000000001\n",
      "f1_score:  0.8200000000000001\n",
      "precision:  1.0\n",
      "recall:  0.8200000000000001\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of intent matching when user refer to what they talked before\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "k = 0\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "while(k < 10):  \n",
    "    with open('intent.json', encoding='utf-8') as file:\n",
    "        data1 = json.load(file)\n",
    "\n",
    "    corpus = [\"What is Americano\", \"How much is it\", \n",
    "              \"How much is decaf coffee\", \"Can i have one of it\", \n",
    "              \"What is Mocha?\", \"Can I have one of it\",\n",
    "              \"What is flat white\", \"Please give me one of it and one black tea\", \n",
    "              \"My name is Hong Shen\", \"What is my name\"]\n",
    "\n",
    "    label = [\"americano price\", \"transaction\", \"transaction\", \"transaction\", \"username\"]\n",
    "\n",
    "    prediction = []\n",
    "    predicted = []\n",
    "    max_len = 20\n",
    "\n",
    "    model1, lbl_encoder1, tokenizer1 = model(data1)\n",
    "\n",
    "    for sentence in corpus:\n",
    "        query = sentence\n",
    "        result = model1.predict(pad_sequences(tokenizer1.texts_to_sequences([query]), truncating='post', maxlen=max_len), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "        tag = lbl_encoder1.inverse_transform([np.argmax(result)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "\n",
    "        for i in data1['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                predicted.append(tag[0])\n",
    "\n",
    "    prediction = [predicted[i] for i in range(1, len(predicted), 2)]\n",
    "\n",
    "    accuracy_list.append(accuracy_score(label, prediction))\n",
    "    precision_list.append(precision_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "    recall_list.append(recall_score(label, prediction, average = 'weighted', zero_division=1))\n",
    "    f1_list.append(f1_score(label, prediction, average='weighted'))\n",
    "    k = k+1\n",
    "    \n",
    "#Print accuracy, precision, recall and f1 score\n",
    "print(\"accurary: \", statistics.mean(accuracy_list))\n",
    "print(\"f1_score: \", statistics.mean(f1_list))\n",
    "print(\"precision: \", statistics.mean(precision_list))\n",
    "print(\"recall: \", statistics.mean(recall_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f56af3-25fe-4c06-92e3-5a111ed0917d",
   "metadata": {},
   "source": [
    "## Average chatbot response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56cc537e-499c-40d7-9351-1281e17edfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Groovy:\n",
      " Hi there\n",
      "Response time:  0.3037\n",
      "\n",
      "Groovy:\n",
      " Hi there\n",
      "Response time:  0.0377\n",
      "\n",
      "Groovy:\n",
      " Hi there\n",
      "Response time:  0.0332\n",
      "\n",
      "Groovy:\n",
      " Hey\n",
      "Response time:  0.0406\n",
      "\n",
      "Groovy:\n",
      " Hi\n",
      "Response time:  0.0349\n",
      "\n",
      "Groovy:\n",
      " I'm Groovy, an Artificial Intelligent bot\n",
      "Response time:  0.0306\n",
      "\n",
      "Groovy:\n",
      " I am fine, thanks for asking.\n",
      "Response time:  0.0455\n",
      "\n",
      "Groovy:\n",
      " Good day!\n",
      "Response time:  0.0303\n",
      "\n",
      "Groovy:\n",
      " Good day!\n",
      "Response time:  0.0402\n",
      "\n",
      "Groovy:\n",
      " I can have a small talk, help to take order and answer some questions regarding the beverages!\n",
      "Response time:  0.0402\n",
      "\n",
      "Groovy:\n",
      "Your name is.\n",
      "Response time:  0.0396\n",
      "\n",
      "Groovy:\n",
      " I'm Groovy, an Artificial Intelligent bot\n",
      "Response time:  0.0347\n",
      "\n",
      "Groovy:\n",
      " I.m Groovy, your bot assistant\n",
      "Response time:  0.0428\n",
      "\n",
      "\n",
      "Menu:\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Espresso\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Americano\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Cappuccino\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Latte\t\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Macchiato\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Flat White\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Mocha\t\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Black Tea\t\t(£1.50)\n",
      "\n",
      "Response time:  0.0409\n",
      "\n",
      "Groovy:\n",
      " Americano also called as black coffee. It is simply just hot water and espresso. It will be served half espresso to half water.\n",
      "Response time:  0.0494\n",
      "Please confirm your order\n",
      "Thank you, your order has been confirmed\n",
      "Response time:  0.0588\n",
      "\n",
      "Groovy:\n",
      " We are using Arabica here.\n",
      "Response time:  0.036\n",
      "\n",
      "Groovy:\n",
      " A cup of Espresso is £1.50\n",
      "Response time:  0.0396\n",
      "\n",
      "Groovy:\n",
      " It is highly depend on your taste of bitterness, sweetness and amount of milk. You can ask about the coffee or tea served in our menu to have an idea of their taste. However, the most popular coffee is cappuccino.\n",
      "Response time:  0.038\n",
      "\n",
      "Groovy:\n",
      " A cup of Cappuccino is £1.80\n",
      "Response time:  0.0301\n",
      "\n",
      "Groovy:\n",
      " Decaf is short for decaffeinated coffee, it has at least 97% of caffeine removed. Unfortunately, we do not sell decaf coffee, sorry for any inconvenience.\n",
      "Response time:  0.0412\n",
      "\n",
      "\n",
      "Menu:\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Espresso\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Americano\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Cappuccino\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Latte\t\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Macchiato\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Flat White\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Mocha\t\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Black Tea\t\t(£1.50)\n",
      "\n",
      "Response time:  0.0391\n",
      "\n",
      "\n",
      "Menu:\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Espresso\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Americano\t\t(£1.50)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Cappuccino\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Latte\t\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Macchiato\t\t(£1.80)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Flat White\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Mocha\t\t\t(£2.10)\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Black Tea\t\t(£1.50)\n",
      "\n",
      "Response time:  0.0372\n",
      "Please confirm your order\n",
      "Thank you, your order has been confirmed\n",
      "Response time:  0.0393\n",
      "Please confirm your order\n",
      "Thank you, your order has been confirmed\n",
      "Response time:  0.0389\n",
      "Please confirm your order\n",
      "Thank you, your order has been confirmed\n",
      "Response time:  0.0362\n",
      "\n",
      "Groovy:\n",
      " Decaf is short for decaffeinated coffee, it has at least 97% of caffeine removed. Unfortunately, we do not sell decaf coffee, sorry for any inconvenience.\n",
      "Response time:  0.0477\n",
      "Please confirm your order\n",
      "Thank you, your order has been confirmed\n",
      "Response time:  0.0417\n",
      "\n",
      "Groovy:\n",
      " Hi there\n",
      "Response time:  0.0423\n",
      "\n",
      "Groovy:\n",
      " Hi there\n",
      "Response time:  0.0506\n",
      "\n",
      "Groovy:\n",
      " Hey\n",
      "Response time:  0.0348\n",
      "\n",
      "Groovy:\n",
      "Noted, your name is John.\n",
      "Response time:  0.0407\n",
      "\n",
      "Groovy:\n",
      "Noted, your name is Hong Shen.\n",
      "Response time:  0.0432\n",
      "\n",
      "Groovy:\n",
      "Noted, your name is Change Muhammad Ali.\n",
      "Response time:  0.0452\n",
      "\n",
      "Groovy:\n",
      "Noted, your name is Replace Sugesh Garnessan.\n",
      "Response time:  0.0527\n",
      "[0.3037, 0.0377, 0.0332, 0.0406, 0.0349, 0.0306, 0.0455, 0.0303, 0.0402, 0.0402, 0.0396, 0.0347, 0.0428, 0.0409, 0.0494, 0.0588, 0.036, 0.0396, 0.038, 0.0301, 0.0412, 0.0391, 0.0372, 0.0393, 0.0389, 0.0362, 0.0477, 0.0417, 0.0423, 0.0506, 0.0348, 0.0407, 0.0432, 0.0452, 0.0527]\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.3607\n",
      "\n",
      "Groovy:\n",
      "I am sorry to hear that, I will feedback to my company.\n",
      "Bye, take care Replace Sugesh Garnessan\n",
      "Response time:  0.0425\n",
      "\n",
      "Groovy:\n",
      "I am sorry to hear that, I will feedback to my company.\n",
      "Bye, take care Replace Sugesh Garnessan\n",
      "Response time:  0.0415\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.0411\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.0403\n",
      "\n",
      "Groovy:\n",
      "I am sorry to hear that, I will feedback to my company.\n",
      "Bye, take care Replace Sugesh Garnessan\n",
      "Response time:  0.0364\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.0359\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.0302\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.0302\n",
      "\n",
      "Groovy:\n",
      "Thank you for your feedback, I am glad to hear that!\n",
      "Response time:  0.0406\n",
      "\n",
      "Total response:  45\n",
      "\n",
      " [0.3037, 0.0377, 0.0332, 0.0406, 0.0349, 0.0306, 0.0455, 0.0303, 0.0402, 0.0402, 0.0396, 0.0347, 0.0428, 0.0409, 0.0494, 0.0588, 0.036, 0.0396, 0.038, 0.0301, 0.0412, 0.0391, 0.0372, 0.0393, 0.0389, 0.0362, 0.0477, 0.0417, 0.0423, 0.0506, 0.0348, 0.0407, 0.0432, 0.0452, 0.0527, 0.3607, 0.0425, 0.0415, 0.0411, 0.0403, 0.0364, 0.0359, 0.0302, 0.0302, 0.0406]\n",
      "\n",
      "Average response time:  0.05282222222222222\n"
     ]
    }
   ],
   "source": [
    "# Calculate avergae chatbot response time\n",
    "import time\n",
    "import statistics\n",
    "import csv\n",
    "# Read question-answer pair in csv file\n",
    "with open('ExperimentQuestions.csv', mode='r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    corpus = list(reader)\n",
    "    \n",
    "with open('intent.json', encoding='utf-8') as file:\n",
    "    data1 = json.load(file)\n",
    "    \n",
    "with open('PositiveNegativeData.json', encoding='utf-8') as file1:\n",
    "    data2 = json.load(file1)\n",
    "        \n",
    "corpus = [sentence for sublist in corpus for sentence in sublist]\n",
    "\n",
    "max_len = 20\n",
    "\n",
    "model1, lbl_encoder1, tokenizer1 = model(data1)\n",
    "model2, lbl_encoder2, tokenizer2 = model(data2)\n",
    "\n",
    "name = ''\n",
    "newName = ''\n",
    "queryList = [\"\",\"\"]\n",
    "response_time = []\n",
    "for sentence in corpus:\n",
    "    query = sentence\n",
    "    queryList[0] = queryList[1]\n",
    "    queryList[1] = query.lower()\n",
    "    start_time = time.time()\n",
    "    result = model1.predict(pad_sequences(tokenizer1.texts_to_sequences([query]), truncating='post', maxlen=max_len), verbose=0) # remove the query from the end when its length exceed max length (20)\n",
    "    tag = lbl_encoder1.inverse_transform([np.argmax(result)]) #transform tag's numerical values back to string (0 -> \"greeting\")\n",
    "\n",
    "    for i in data1['intents']:\n",
    "        if i['tag'] == tag:\n",
    "            response = np.random.choice(i['responses'])\n",
    "            if response == \"Menu\":\n",
    "                openMenu()                  \n",
    "            elif response == \"transaction\":\n",
    "                print(\"Please confirm your order\")\n",
    "                print(\"Thank you, your order has been confirmed\")\n",
    "            elif response == \"username\":\n",
    "                print(\"\\nGroovy:\\nYour name is\" + (newName if len(newName)!= 0 else name) + \".\")\n",
    "            elif response == \"Change name\":\n",
    "                newName = NER(query)\n",
    "                print(\"\\nGroovy:\\nNoted, your name is\" + (newName if len(newName)!= 0 else name) + \".\")\n",
    "            else:\n",
    "                print(\"\\nGroovy:\\n\", response)\n",
    "            end_time = time.time()\n",
    "            response_time.append(round(end_time - start_time, 4)) # calculate response time\n",
    "            print(\"Response time: \", response_time[-1])\n",
    "print(response_time)\n",
    "\n",
    "# sentiment analysis response time\n",
    "corpus = [\"That was very helpful, thank you!\",\n",
    "          \"I didn't quite understand your response.\",\n",
    "          \"Your chatbot needs improvement in understanding natural language.\",\n",
    "          \"Your chatbot is doing a great job at answering my questions!\",\n",
    "          \"That was a quick and accurate response, good job!\",\n",
    "          \"I'm not satisfied with your chatbot's response, can you provide more information?\",\n",
    "          \"Your chatbot is very informative and easy to use.\",\n",
    "          \"I think your chatbot misunderstood my question, can you clarify?\",\n",
    "          \"good\",\n",
    "          \"bad\"]\n",
    "\n",
    "for query in corpus:\n",
    "    start_time = time.time()\n",
    "    prediction = feedback(query, model2, tokenizer2, lbl_encoder2)\n",
    "    if(prediction==True):\n",
    "        print('\\nGroovy:\\nThank you for your feedback, I am glad to hear that!')\n",
    "    else:\n",
    "        print('\\nGroovy:\\nI am sorry to hear that, I will feedback to my company.')\n",
    "        print(\"Bye, take care\"+ (newName if len(newName)!=0 else name))\n",
    "    end_time = time.time()\n",
    "    response_time.append(round(end_time - start_time, 4)) # calculate response time\n",
    "    print(\"Response time: \", response_time[-1])\n",
    "\n",
    "print(\"\\nTotal response: \",len(response_time))\n",
    "print(\"\\n\",response_time)\n",
    "\n",
    "# calculate average response time\n",
    "avg_response_time = statistics.mean(response_time)\n",
    "print(\"\\nAverage response time: \", avg_response_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be0483-c03c-4194-83e3-1f4a56d1d2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
